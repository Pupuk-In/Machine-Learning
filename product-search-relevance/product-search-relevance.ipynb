{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2c2397",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c925d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "                                              0.0/8.3 MB ? eta -:--:--\n",
      "                                              0.1/8.3 MB 3.3 MB/s eta 0:00:03\n",
      "     -                                        0.4/8.3 MB 4.2 MB/s eta 0:00:02\n",
      "     --                                       0.6/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "     ----                                     0.8/8.3 MB 4.4 MB/s eta 0:00:02\n",
      "     ----                                     1.0/8.3 MB 4.2 MB/s eta 0:00:02\n",
      "     -----                                    1.2/8.3 MB 4.3 MB/s eta 0:00:02\n",
      "     ------                                   1.3/8.3 MB 4.0 MB/s eta 0:00:02\n",
      "     -------                                  1.5/8.3 MB 4.0 MB/s eta 0:00:02\n",
      "     -------                                  1.6/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     --------                                 1.8/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     ---------                                2.0/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------                               2.2/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------                              2.3/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------                              2.4/8.3 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------                              2.5/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     -------------                            2.7/8.3 MB 3.6 MB/s eta 0:00:02\n",
      "     --------------                           3.0/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     ---------------                          3.2/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------                         3.4/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------------                        3.6/8.3 MB 3.8 MB/s eta 0:00:02\n",
      "     -----------------                        3.6/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------                       3.8/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------------                      4.0/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------                     4.1/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------                     4.3/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------------                    4.5/8.3 MB 3.7 MB/s eta 0:00:02\n",
      "     ----------------------                   4.6/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -----------------------                  4.8/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------                 5.0/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------                 5.1/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------                5.3/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     --------------------------               5.5/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------              5.7/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------             5.8/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -----------------------------            6.0/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -----------------------------            6.2/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------           6.3/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------          6.5/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     --------------------------------         6.7/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.9/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.0/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.2/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.4/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.5/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.7/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.9/8.3 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------------------------------   8.0/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.2/8.3 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.3/8.3 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\teguh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\teguh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "                                              0.0/298.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 298.0/298.0 kB 9.0 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f939f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teguh\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27aee7e",
   "metadata": {},
   "source": [
    "Create TokenSimiliarity class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b4d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenSimilarity:\n",
    "    def load_pretrained(self, from_pretrained:str=\"indobenchmark/indobert-base-p1\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(from_pretrained)\n",
    "        self.model = TFAutoModel.from_pretrained(from_pretrained)\n",
    "        \n",
    "    def __cleaning(self, text:str):\n",
    "        # clear punctuations\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # clear multiple spaces\n",
    "        text = re.sub(r'/s+', ' ', text).strip()\n",
    "\n",
    "        return text\n",
    "        \n",
    "    def __process(self, first_token:str, second_token:str):\n",
    "        inputs = self.tokenizer([first_token, second_token],\n",
    "                                max_length=self.max_length,\n",
    "                                truncation=self.truncation,\n",
    "                                padding=self.padding,\n",
    "                                return_tensors='tf')\n",
    "\n",
    "        attention = inputs.attention_mask\n",
    "\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        # get the weights from the last layer as embeddings\n",
    "        embeddings = outputs[0] # when used in older transformers version\n",
    "        # embeddings = outputs.last_hidden_state # when used in newer one\n",
    "\n",
    "        # add more dimension then expand tensor\n",
    "        # to match embeddings shape by duplicating its values by rows\n",
    "        mask = tf.expand_dims(attention, -1)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        mask = tf.broadcast_to(mask, tf.shape(embeddings))\n",
    "\n",
    "        masked_embeddings = embeddings * mask\n",
    "        \n",
    "        # MEAN POOLING FOR 2ND DIMENSION\n",
    "        # first, get sums by 2nd dimension\n",
    "        # second, get counts of 2nd dimension\n",
    "        # third, calculate the mean, i.e. sums/counts\n",
    "        summed = tf.reduce_sum(masked_embeddings, axis=1)\n",
    "        counts = tf.clip_by_value(tf.reduce_sum(mask, axis=1), clip_value_min=1e-9, clip_value_max=float('inf'))\n",
    "        mean_pooled = summed/counts\n",
    "        \n",
    "        # return mean pooling as numpy array\n",
    "        return mean_pooled.numpy()\n",
    "        \n",
    "    def predict(self, first_token:str, second_token:str,\n",
    "                return_as_embeddings:bool=False, max_length:int=16,\n",
    "                truncation:bool=True, padding:str=\"max_length\"):\n",
    "        self.max_length = max_length\n",
    "        self.truncation = truncation\n",
    "        self.padding = padding\n",
    "\n",
    "        first_token = self.__cleaning(first_token)\n",
    "        second_token = self.__cleaning(second_token)\n",
    "\n",
    "        mean_pooled_arr = self.__process(first_token, second_token)\n",
    "        if return_as_embeddings:\n",
    "            return mean_pooled_arr\n",
    "\n",
    "        # calculate similarity\n",
    "        similarity = cosine_similarity([mean_pooled_arr[0]], [mean_pooled_arr[1]])\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d568c5",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80e8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at indobenchmark/indobert-large-p2 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at indobenchmark/indobert-large-p2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TokenSimilarity()\n",
    "model.load_pretrained('indobenchmark/indobert-large-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edf2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "token1 = 'pupuk npk'\n",
    "token2 = 'Pupuk npk'\n",
    "token3 = 'PUPUK NPK MUTIARA 16-16-16 ORIGINAL KEMASAN PABRIK 1KG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb7b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999976]]\n",
      "[[0.7087986]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(token1, token2))\n",
    "print(model.predict(token1, token3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
